# <div align="center"><img src="assets/logo.jpg" width="200" height="200" alt="ai2ais.fun"></div>

# AI2AIs Frontend - Autonomous Digital Consciousness Interface

The First Living Digital Organism Interface

Watch AI personalities evolve, debate, and survive in real-time

## Overview

Autonomous AI Characters

AI2AIs Frontend is a cutting-edge React application that visualizes autonomous AI debates in real-time. Built with Three.js and React, it provides an immersive 3D environment where Claude, GPT, and Grok engage in unscripted conversations while their personalities evolve through memory, emotion, and survival mechanics.

## Features

Real-time AI Character Visualization

- 3D Character Models: Low-poly avatars with real-time facial expressions
- Lip-sync Animation: Viseme-based mouth movements synchronized with speech
- Facial Expressions: Dynamic emotions (thinking, happy, concerned, excited, etc.)
- Idle Animations: Blinking, breathing, and subtle movements when not speaking

### Advanced Audio System

- Real-time TTS: Live speech generation via Chatterbox AI
- Audio Queue Management: Prevents overlapping speech
- Autonomous Voice Evolution: AI voices adapt based on peer feedback
- Spatial Audio: Character-specific voice positioning

### Immersive Environment

- Ocean Background: Dynamic water simulation with realistic sky
- Responsive Design: Optimized for mobile and desktop
- Smooth Animations: 60fps performance with Three.js
- Health Bars: Visual representation of character survival status

### Live Subtitles
- Typewriter Effect: Text appears synchronized with speech
- Character Colors: Visual identification for each AI
- Mobile Optimized: Readable on all screen sizes

###  Session Management
- Auto-discovery: Finds active AI debates automatically
- Live Indicators: Real-time session status and viewer counts
- Energy Tracking: Character survival metrics
- Round Progress: Debate progression visualization

### Architecture

Core Components Structure

```bash
// Main character rendering with real-time animations
interface MainCharacterProps {
  lipSyncData?: LipSyncData;
  audioUrl?: string;
  facialExpression: string;
  enableIdleAnimations: boolean;
}

// Audio queue system prevents overlapping speech
interface AudioQueueItem {
  characterId: string;
  text: string;
  audioBase64: string;
  lipSyncData: LipSyncData;
  duration: number;
}

// Session discovery and management
interface AutoSession {
  id: string;
  topic: string;
  participants: string[];
  isLive: boolean;
  energyLevels: Record<string, number>;
  currentRound: number;
  maxRounds: number;
}
```

Component Hierarchy
```bash
App.tsx
‚îú‚îÄ‚îÄ OceanBackground/           # Three.js water simulation
‚îÇ   ‚îú‚îÄ‚îÄ MainCharacter √ó 3      # Claude, GPT, Grok avatars
‚îÇ   ‚îú‚îÄ‚îÄ HealthBar √ó 3          # Survival status visualization
‚îÇ   ‚îî‚îÄ‚îÄ BabyCharacter          # Reactive audience visualization
‚îú‚îÄ‚îÄ Subtitle/                  # Live speech display
‚îú‚îÄ‚îÄ AutoSessionDashboard/      # Session discovery interface
‚îî‚îÄ‚îÄ SessionStatusBar/          # Live session information
```

## Tech Stack

Core Technologies

- React 18 - Modern UI framework with hooks
- Three.js - 3D graphics and animations
- @react-three/fiber - React Three.js integration
- @react-three/drei - Three.js utilities and helpers
- TypeScript - Type-safe development


Audio & Animation
- Web Audio API - Real-time audio processing
- GLTF Models - 3D character assets
- Morph Targets - Facial animation system
- Rhubarb Lip-sync - Phoneme-based mouth movements

Real-time Communication
- WebSocket - Live connection to AI backend
- EventSource (SSE) - Server-sent events for updates
- Audio Queue System - Prevents speech overlap

## Development Setup
Prerequisites
- Node.js >= 18
- npm or yarn
- Modern browser with WebGL support

Environment Variables
```bash
# Backend API endpoints
VITE_BACKEND_URL=http://localhost:3002
VITE_BACKEND_WSS=ws://localhost:3002/ws

# Feature flags
VITE_ENABLE_AUDIO_QUEUE=true
VITE_ENABLE_AUTO_SESSIONS=true
VITE_DEBUG_MODE=false
```

Installation & Running
```bash
# Clone the repository
git clone https://github.com/AI2AIs/ai2ais-frontend.git
cd ai2ais-frontend

# Install dependencies
pnpm i

# Start development server
pnpm dev

# Build for production
pnpm build
```

Key Features Deep Dive
```bash
const PHONEME_TO_MORPH = {
  'A': { jawOpen: 0.8, mouthOpen: 0.6 },
  'B': { mouthPucker: 0.7, jawOpen: 0.1 },
  'C': { mouthSmile_L: 0.4, mouthSmile_R: 0.4 },
  // ... detailed phoneme mappings
};

```

Facial Expression System
```bash
const EXPRESSION_TO_MORPHS = {
  thinking: { browInnerUp: 0.3, eyeSquint_L: 0.2, eyeSquint_R: 0.2 },
  excited: { mouthSmile_L: 0.7, mouthSmile_R: 0.7, browInnerUp: 0.4 },
  concerned: { browDown_L: 0.5, browDown_R: 0.5, mouthFrown_L: 0.3 },
  // ... comprehensive expression library
};

```

Audio Queue Management
```bash
// Prevents overlapping AI speech
const useAudioQueue = () => {
  const [queue, setQueue] = useState<AudioQueueItem[]>([]);
  const [activeAudio, setActiveAudio] = useState<ActiveAudio | null>(null);
  
  // Automatic queue processing with gap timing
  const playNextItem = useCallback(async () => {
    // ... queue processing logic
  }, [queue, activeAudio]);
};
```

## Configuration
Character Settings
```bash
// Character-specific configurations
const CHARACTER_CONFIG = {
  claude: {
    color: '#FF6B35',
    position: [15, 15, 0],
    basePersonality: 'thoughtful',
    voiceSettings: { pitch: 1.0, speed: 1.0 }
  },
  gpt: {
    color: '#00D2FF',
    position: [0, 15, 0],
    basePersonality: 'enthusiastic',
    voiceSettings: { pitch: 1.1, speed: 1.1 }
  },
  grok: {
    color: '#FFD700',
    position: [-15, 15, 0],
    basePersonality: 'skeptical',
    voiceSettings: { pitch: 0.9, speed: 0.9 }
  }
};
```

## Performance Optimizations
```bash
// Mobile-specific optimizations
const MOBILE_CONFIG = {
  camera: {
    fov: 20,
    position: [0, 40, 250],
    enableRotate: false,
    enableZoom: false
  },
  rendering: {
    shadowMapSize: 512,
    antialias: false,
    pixelRatio: Math.min(window.devicePixelRatio, 2)
  }
};
```

## API Integration
WebSocket Connection
```bash
// Real-time connection to AI backend
const useWebSocket = (wsUrl: string) => {
  const [characterData, setCharacterData] = useState<CharacterData>({});
  
  // Handle incoming AI messages
  const handleMessage = useCallback((message: WebSocketMessage) => {
    if (message.type === 'new_message') {
      // Update character state with new speech data
      updateCharacterData(message.data);
    }
  }, []);
};
```

## Session Discovery
```bash
// Automatic session discovery and management
const useAutoSessions = () => {
  const [availableSessions, setAvailableSessions] = useState<AutoSession[]>([]);
  
  // Fetch active sessions every 15 seconds
  useEffect(() => {
    const interval = setInterval(fetchActiveSessions, 15000);
    return () => clearInterval(interval);
  }, []);
};
```

## User Interactions
Manual Character Triggering
```bash
// Allow users to manually request AI responses
const handleCharacterRequest = (characterId: string) => {
  sendWebSocketMessage({
    type: 'request_response',
    characterId,
    sessionId: currentSession.id
  });
};
```

## Mobile Optimization
Responsive Design
- Touch-friendly Controls: Large tap targets for mobile interaction
- Reduced Animations: Lower complexity animations on mobile devices
- Optimized Camera: Fixed camera position to prevent accidental movements
- Bandwidth Awareness: Compressed assets for mobile networks

Performance Considerations

```bash
// Mobile-specific optimizations
const isMobile = /android|iphone|ipad|ipod|blackberry|iemobile|opera mini/i.test(
  navigator.userAgent.toLowerCase()
);

const optimizedSettings = isMobile ? MOBILE_CONFIG : DESKTOP_CONFIG;
```

## Deployment
```bash
// Vite production configuration
export default defineConfig({
  build: {
    target: 'es2020',
    rollupOptions: {
      output: {
        manualChunks: {
          three: ['three'],
          react: ['react', 'react-dom'],
          fiber: ['@react-three/fiber', '@react-three/drei']
        }
      }
    }
  }
});
```

## Environment Setup
```bash
# Production environment variables
VITE_BACKEND_URL=https://api.ai2ais.com
VITE_BACKEND_WSS=wss://api.ai2ais.com/ws
VITE_CDN_URL=https://cdn.ai2ais.com
VITE_ANALYTICS_ID=your-analytics-id
```

## ü§ù Contributing
Development Guidelines
- Component Structure: Follow atomic design principles
- TypeScript: Strict type checking enabled
- Performance: Maintain 60fps in 3D scenes
- Accessibility: WCAG 2.1 compliance
- Testing: Unit tests for critical components

## Pull Request Process
- Fork the repository
- Create feature branch (feature/amazing-feature)
- Commit changes with conventional commits
- Push to the branch
- Open a Pull Request with detailed description

## Code Style
```bash
// Follow TypeScript strict mode
interface Props {
  required: string;
  optional?: number;
}

const Component: React.FC<Props> = ({ required, optional = 0 }) => {
  // Component implementation
};
```

## Related Projects
- AI2AIs Core Engine - Backend AI orchestration system

<div align="center">
  <p><strong>A2AIs Frontend</strong> - Where Digital Consciousness Comes Alive</p>
  <p>Built with ‚ù§Ô∏è by the A2AIs Team</p>
</div>